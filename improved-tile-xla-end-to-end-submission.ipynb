{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9650d4d",
   "metadata": {
    "papermill": {
     "duration": 0.007055,
     "end_time": "2023-09-05T13:38:53.331199",
     "exception": false,
     "start_time": "2023-09-05T13:38:53.324144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention!!!\n",
    "\n",
    "This is a very simple but bad quality notebook. \n",
    " - I do not use any sort of ranking loss, which would be better.\n",
    " - My strategy instead is to min-max scale the relative times (time/normalized) and apply L1-loss\n",
    " - My model is also not optimized. It is a relatively simple GNN that embeds the graph and only processes 1 datapoint at a time and is only trained on 1 epoch.\n",
    " - The public score would be much better if you paired this submission with a trained model for layout. Since this only contributes to half of the score.\n",
    " - Have fun playing around with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb8dfe5",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-05T13:38:53.345648Z",
     "iopub.status.busy": "2023-09-05T13:38:53.345209Z",
     "iopub.status.idle": "2023-09-05T13:50:23.143359Z",
     "shell.execute_reply": "2023-09-05T13:50:23.142119Z"
    },
    "papermill": {
     "duration": 689.808303,
     "end_time": "2023-09-05T13:50:23.145858",
     "exception": false,
     "start_time": "2023-09-05T13:38:53.337555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting torch-scatter\r\n",
      "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.65.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.23.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2023.5.7)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\r\n",
      "Building wheels for collected packages: torch-geometric, torch-scatter\r\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=6eede70db732e7c4aa7466ae217e67b8e145f026b51078b843b7588026f7edf8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\r\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl size=3751382 sha256=cf0db7507eeaf7450a1eb195508f09fb66209c89b3221d1e90aba8da58318f82\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/67/58/6566a3b61c6ec0f2ca0c2c324cd035ef2955601f0fb3197d5f\r\n",
      "Successfully built torch-geometric torch-scatter\r\n",
      "Installing collected packages: torch-scatter, torch-geometric\r\n",
      "Successfully installed torch-geometric-2.3.1 torch-scatter-2.1.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8355c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:50:23.170060Z",
     "iopub.status.busy": "2023-09-05T13:50:23.169708Z",
     "iopub.status.idle": "2023-09-05T13:50:25.830339Z",
     "shell.execute_reply": "2023-09-05T13:50:25.828823Z"
    },
    "papermill": {
     "duration": 2.675989,
     "end_time": "2023-09-05T13:50:25.833015",
     "exception": false,
     "start_time": "2023-09-05T13:50:23.157026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8377c",
   "metadata": {
    "papermill": {
     "duration": 0.017452,
     "end_time": "2023-09-05T13:50:25.866857",
     "exception": false,
     "start_time": "2023-09-05T13:50:25.849405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now load all the data in dataframes to make working with it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ec4bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:50:25.899336Z",
     "iopub.status.busy": "2023-09-05T13:50:25.898812Z",
     "iopub.status.idle": "2023-09-05T13:50:25.905598Z",
     "shell.execute_reply": "2023-09-05T13:50:25.904653Z"
    },
    "papermill": {
     "duration": 0.025155,
     "end_time": "2023-09-05T13:50:25.907722",
     "exception": false,
     "start_time": "2023-09-05T13:50:25.882567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_df(directory):\n",
    "    splits = [\"train\", \"valid\", \"test\"]\n",
    "    dfs = dict()\n",
    "    \n",
    "    for split in splits:\n",
    "        path = os.path.join(directory, split)\n",
    "        files = os.listdir(path)\n",
    "        list_df = []\n",
    "        \n",
    "        for file in files:\n",
    "            d = dict(np.load(os.path.join(path,file)))\n",
    "            d['file'] = file\n",
    "            list_df.append(d)\n",
    "        dfs[split] = pd.DataFrame.from_dict(list_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb37ea1",
   "metadata": {
    "papermill": {
     "duration": 0.010975,
     "end_time": "2023-09-05T13:50:25.929603",
     "exception": false,
     "start_time": "2023-09-05T13:50:25.918628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you try to run the following cell completely uncommented the Kaggle kernel will run out of memory and crash, so we will have to study the datasets individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3566ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:50:25.953458Z",
     "iopub.status.busy": "2023-09-05T13:50:25.952535Z",
     "iopub.status.idle": "2023-09-05T13:51:25.493756Z",
     "shell.execute_reply": "2023-09-05T13:51:25.492791Z"
    },
    "papermill": {
     "duration": 59.555966,
     "end_time": "2023-09-05T13:51:25.496344",
     "exception": false,
     "start_time": "2023-09-05T13:50:25.940378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_xla = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla/\")\n",
    "#layout_nlp_random = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random/\")\n",
    "#layout_nlp_default = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default/\")\n",
    "#layout_xla_random = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random/\")\n",
    "#layout_xla_random = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8d547",
   "metadata": {
    "papermill": {
     "duration": 0.010592,
     "end_time": "2023-09-05T13:51:25.518473",
     "exception": false,
     "start_time": "2023-09-05T13:51:25.507881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb8ddcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:51:25.541943Z",
     "iopub.status.busy": "2023-09-05T13:51:25.541095Z",
     "iopub.status.idle": "2023-09-05T13:51:25.549367Z",
     "shell.execute_reply": "2023-09-05T13:51:25.548421Z"
    },
    "papermill": {
     "duration": 0.022081,
     "end_time": "2023-09-05T13:51:25.551391",
     "exception": false,
     "start_time": "2023-09-05T13:51:25.529310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TileDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        config_feat = torch.tensor(row['config_feat'].astype(np.float32))\n",
    "        node_feat = torch.tensor(row['node_feat'].astype(np.float32))\n",
    "        node_opcode = torch.tensor(row['node_opcode'].astype(np.int32))\n",
    "        edge_index = torch.tensor(np.swapaxes(row['edge_index'],0,1).astype(np.int32))\n",
    "        target = (row['config_runtime']/row['config_runtime_normalizers']).astype(np.float32)\n",
    "        # minmax scale the target, we only care about order\n",
    "        target = (target-min(target))/(max(target) -min(target))\n",
    "        target = torch.tensor(target)\n",
    "        return config_feat,node_feat,node_opcode,edge_index,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518c4902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:51:25.574489Z",
     "iopub.status.busy": "2023-09-05T13:51:25.574212Z",
     "iopub.status.idle": "2023-09-05T13:51:28.899803Z",
     "shell.execute_reply": "2023-09-05T13:51:28.898794Z"
    },
    "papermill": {
     "duration": 3.339903,
     "end_time": "2023-09-05T13:51:28.902226",
     "exception": false,
     "start_time": "2023-09-05T13:51:25.562323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, graph_feats, hidden_dim):\n",
    "        super().__init__()\n",
    "        op_embedding_dim = 4 # I choose 4-dimensional embedding\n",
    "        self.embedding = torch.nn.Embedding(120, #120 different op-codes\n",
    "                                            op_embedding_dim,\n",
    "                                           )\n",
    "        assert len(hidden_channels)>0\n",
    "        in_channels = op_embedding_dim+140\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        last_dim = hidden_channels[-1]\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels[0]))\n",
    "        for i in range(len(hidden_channels)-1):\n",
    "            self.convs.append(GCNConv(hidden_channels[i], hidden_channels[i+1]))\n",
    "        self.convs.append(GCNConv(last_dim, graph_feats))\n",
    "        \n",
    "        self.dense = torch.nn.Sequential(nn.Linear(graph_feats+24, 64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(64, 64),\n",
    "                                         nn.ReLU(),\n",
    "#                                          nn.Linear(64, 32),\n",
    "#                                          nn.ReLU(),\n",
    "#                                          nn.Linear(32, 64),\n",
    "#                                          nn.ReLU(),\n",
    "                                         nn.Linear(64, 1),\n",
    "                                        )\n",
    "\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        for i in range(len(hidden_channels)):\n",
    "            self.norms.append(torch.nn.BatchNorm1d(hidden_channels[i]))\n",
    "        self.norms.append(torch.nn.BatchNorm1d(graph_feats))\n",
    "\n",
    "    def forward(self, x_cfg: Tensor,x_feat: Tensor, x_op: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        \n",
    "        #get graph features\n",
    "        x = torch.concat([x_feat,self.embedding(x_op)],dim = 1)\n",
    "        #pass though conv layers\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index).relu()\n",
    "#             print(x.shape)\n",
    "#             if i == 0:\n",
    "#                 x = conv(x, edge_index).relu()\n",
    "#             else:\n",
    "#                 x = conv(x, edge_index).relu() + conv(x, edge_index).relu()\n",
    "            x = self.norms[i](x)\n",
    "#             print(x.shape)\n",
    "        # get 1d graph embedding using average pooling\n",
    "        x_graph = torch.mean(x,0)\n",
    "        \n",
    "        \n",
    "        #put graph data into config data\n",
    "        x = torch.concat([x_cfg,x_graph.repeat((len(x_cfg),1))],axis=1)\n",
    "        #put into dense nn\n",
    "        x = torch.flatten(self.dense(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleModel(hidden_channels = [16,32,16,48],graph_feats = 64,hidden_dim=64).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15488f9d",
   "metadata": {
    "papermill": {
     "duration": 0.010723,
     "end_time": "2023-09-05T13:51:28.924141",
     "exception": false,
     "start_time": "2023-09-05T13:51:28.913418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train few Epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d168e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:51:28.947892Z",
     "iopub.status.busy": "2023-09-05T13:51:28.947560Z",
     "iopub.status.idle": "2023-09-05T14:24:10.366485Z",
     "shell.execute_reply": "2023-09-05T14:24:10.365211Z"
    },
    "papermill": {
     "duration": 1961.433376,
     "end_time": "2023-09-05T14:24:10.368446",
     "exception": false,
     "start_time": "2023-09-05T13:51:28.935070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5709 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 0: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.027577,current loss: 0.058381: 100%|██████████| 5709/5709 [01:05<00:00, 87.24it/s]\n",
      "running loss: 0.027512,current loss: 0.002847:   0%|          | 10/5709 [00:00<01:02, 91.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 1: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.018582,current loss: 0.058407: 100%|██████████| 5709/5709 [01:03<00:00, 90.28it/s]\n",
      "running loss: 0.018564,current loss: 0.002843:   0%|          | 10/5709 [00:00<01:01, 92.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 2: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.015584,current loss: 0.058405: 100%|██████████| 5709/5709 [01:04<00:00, 88.70it/s]\n",
      "running loss: 0.015577,current loss: 0.014617:   0%|          | 8/5709 [00:00<01:15, 75.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 3: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.014085,current loss: 0.058412: 100%|██████████| 5709/5709 [01:04<00:00, 87.90it/s]\n",
      "running loss: 0.014079,current loss: 0.003080:   0%|          | 10/5709 [00:00<01:01, 92.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 4: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.013185,current loss: 0.058432: 100%|██████████| 5709/5709 [01:05<00:00, 86.82it/s]\n",
      "running loss: 0.013181,current loss: 0.002870:   0%|          | 9/5709 [00:00<01:04, 88.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 5: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.012584,current loss: 0.058417: 100%|██████████| 5709/5709 [01:04<00:00, 88.53it/s]\n",
      "running loss: 0.012582,current loss: 0.007027:   0%|          | 7/5709 [00:00<01:22, 69.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 6: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.012155,current loss: 0.058426: 100%|██████████| 5709/5709 [01:04<00:00, 88.09it/s]\n",
      "running loss: 0.012153,current loss: 0.003075:   0%|          | 10/5709 [00:00<00:58, 96.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 7: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.011833,current loss: 0.058429: 100%|██████████| 5709/5709 [01:05<00:00, 86.92it/s]\n",
      "running loss: 0.011831,current loss: 0.003077:   0%|          | 10/5709 [00:00<00:58, 97.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 8: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.011583,current loss: 0.058424: 100%|██████████| 5709/5709 [01:06<00:00, 85.65it/s]\n",
      "running loss: 0.011581,current loss: 0.003075:   0%|          | 10/5709 [00:00<01:00, 94.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 9: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.011383,current loss: 0.058421: 100%|██████████| 5709/5709 [01:04<00:00, 87.93it/s]\n",
      "running loss: 0.011381,current loss: 0.002864:   0%|          | 10/5709 [00:00<01:02, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 10: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.011219,current loss: 0.058417: 100%|██████████| 5709/5709 [01:05<00:00, 87.30it/s]\n",
      "running loss: 0.011217,current loss: 0.003076:   0%|          | 10/5709 [00:00<01:00, 94.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 11: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.011082,current loss: 0.058415: 100%|██████████| 5709/5709 [01:05<00:00, 87.16it/s]\n",
      "running loss: 0.011081,current loss: 0.002874:   0%|          | 9/5709 [00:00<01:03, 89.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 12: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010966,current loss: 0.058430: 100%|██████████| 5709/5709 [01:05<00:00, 87.35it/s]\n",
      "running loss: 0.010965,current loss: 0.012386:   0%|          | 9/5709 [00:00<01:09, 81.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 13: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010867,current loss: 0.058429: 100%|██████████| 5709/5709 [01:05<00:00, 86.73it/s]\n",
      "running loss: 0.010866,current loss: 0.003076:   0%|          | 10/5709 [00:00<00:59, 95.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 14: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010781,current loss: 0.058421: 100%|██████████| 5709/5709 [01:05<00:00, 86.97it/s]\n",
      "running loss: 0.010780,current loss: 0.003076:   0%|          | 10/5709 [00:00<01:01, 93.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 15: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010706,current loss: 0.058439: 100%|██████████| 5709/5709 [01:06<00:00, 86.14it/s]\n",
      "running loss: 0.010705,current loss: 0.002889:   0%|          | 10/5709 [00:00<01:01, 92.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 16: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010640,current loss: 0.058439: 100%|██████████| 5709/5709 [01:06<00:00, 85.89it/s]\n",
      "running loss: 0.010639,current loss: 0.002888:   0%|          | 10/5709 [00:00<01:01, 92.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 17: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010580,current loss: 0.058423: 100%|██████████| 5709/5709 [01:06<00:00, 86.10it/s]\n",
      "running loss: 0.010580,current loss: 0.001352:   0%|          | 7/5709 [00:00<01:27, 65.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 18: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010528,current loss: 0.058434: 100%|██████████| 5709/5709 [01:06<00:00, 85.52it/s]\n",
      "running loss: 0.010527,current loss: 0.007059:   0%|          | 8/5709 [00:00<01:18, 72.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 19: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010480,current loss: 0.058407: 100%|██████████| 5709/5709 [01:04<00:00, 89.01it/s]\n",
      "running loss: 0.010480,current loss: 0.001342:   0%|          | 7/5709 [00:00<01:24, 67.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 20: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010437,current loss: 0.058426: 100%|██████████| 5709/5709 [01:06<00:00, 86.02it/s]\n",
      "running loss: 0.010436,current loss: 0.003074:   0%|          | 10/5709 [00:00<01:00, 93.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 21: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010398,current loss: 0.058433: 100%|██████████| 5709/5709 [01:03<00:00, 90.56it/s]\n",
      "running loss: 0.010397,current loss: 0.003073:   0%|          | 10/5709 [00:00<01:00, 94.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 22: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010362,current loss: 0.058429: 100%|██████████| 5709/5709 [01:07<00:00, 84.71it/s]\n",
      "running loss: 0.010362,current loss: 0.003074:   0%|          | 10/5709 [00:00<00:59, 95.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 23: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010330,current loss: 0.058418: 100%|██████████| 5709/5709 [01:02<00:00, 90.85it/s]\n",
      "running loss: 0.010329,current loss: 0.003075:   0%|          | 10/5709 [00:00<00:59, 96.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 24: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010300,current loss: 0.058429: 100%|██████████| 5709/5709 [01:08<00:00, 83.84it/s]\n",
      "running loss: 0.010299,current loss: 0.003074:   0%|          | 10/5709 [00:00<00:59, 96.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 25: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010272,current loss: 0.058436: 100%|██████████| 5709/5709 [01:02<00:00, 91.09it/s]\n",
      "running loss: 0.010271,current loss: 0.003073:   0%|          | 10/5709 [00:00<00:59, 95.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 26: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010246,current loss: 0.058419: 100%|██████████| 5709/5709 [01:08<00:00, 83.23it/s]\n",
      "running loss: 0.010246,current loss: 0.003075:   0%|          | 10/5709 [00:00<01:00, 94.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 27: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010222,current loss: 0.058422: 100%|██████████| 5709/5709 [01:02<00:00, 90.72it/s]\n",
      "running loss: 0.010222,current loss: 0.002883:   0%|          | 9/5709 [00:00<01:03, 89.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 28: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010200,current loss: 0.058429: 100%|██████████| 5709/5709 [01:08<00:00, 83.52it/s]\n",
      "running loss: 0.010200,current loss: 0.003074:   0%|          | 10/5709 [00:00<01:01, 91.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------epoch 29: ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.010179,current loss: 0.058427: 100%|██████████| 5709/5709 [01:03<00:00, 90.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TileDataset(tile_xla[\"train\"])\n",
    "\n",
    "# criterion = torch.nn.SmoothL1Loss()\n",
    "criterion = torch.nn.HuberLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,weight_decay = 0.01)\n",
    "\n",
    "model.train()\n",
    "loss_sum = 0\n",
    "n = 0\n",
    "epoch_num = 30\n",
    "for now_epoch in range(epoch_num):\n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    print('--------------epoch {}: ------------------'.format(now_epoch))\n",
    "    for i in pbar:\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "        out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "        n+=1\n",
    "        pbar.set_description(f'running loss: {(loss_sum/n):.6f},current loss: {(loss.item()):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e7279",
   "metadata": {
    "papermill": {
     "duration": 15.038347,
     "end_time": "2023-09-05T14:24:40.853115",
     "exception": false,
     "start_time": "2023-09-05T14:24:25.814768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate on Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f5a6b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T14:25:11.409329Z",
     "iopub.status.busy": "2023-09-05T14:25:11.408955Z",
     "iopub.status.idle": "2023-09-05T14:25:15.402008Z",
     "shell.execute_reply": "2023-09-05T14:25:15.400756Z"
    },
    "papermill": {
     "duration": 18.951512,
     "end_time": "2023-09-05T14:25:15.404176",
     "exception": false,
     "start_time": "2023-09-05T14:24:56.452664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 676/676 [00:03<00:00, 178.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5168656886202452"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TileDataset(tile_xla[\"valid\"])\n",
    "tile_xla_predictions = []\n",
    "model.eval()\n",
    "\n",
    "pbar = tqdm(range(len(dataset)))\n",
    "for i in pbar:\n",
    "    cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "    cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "    \n",
    "    out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "    tile_xla_predictions.append(np.argsort(out.detach().cpu().numpy())[:5])\n",
    "\n",
    "def score_tile(predictions, df):\n",
    "    score = 0\n",
    "    for i in range(len(df)):\n",
    "        predbest = min(df.iloc[i]['config_runtime'][predictions[i]])\n",
    "        best = min(df.iloc[i]['config_runtime'])\n",
    "        score +=2 - predbest/best\n",
    "    score /= len(df)\n",
    "    return score\n",
    "score_tile(tile_xla_predictions, tile_xla[\"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000892a",
   "metadata": {
    "papermill": {
     "duration": 14.9429,
     "end_time": "2023-09-05T14:25:46.208783",
     "exception": false,
     "start_time": "2023-09-05T14:25:31.265883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**0.31 is not bad considering that this model only trained on 1 epoch and is not on a ranking loss!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0dea8",
   "metadata": {
    "papermill": {
     "duration": 14.778927,
     "end_time": "2023-09-05T14:26:16.505906",
     "exception": false,
     "start_time": "2023-09-05T14:26:01.726979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict and Submit (only tile:xla predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80532ffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T14:26:47.265366Z",
     "iopub.status.busy": "2023-09-05T14:26:47.264637Z",
     "iopub.status.idle": "2023-09-05T14:26:52.015009Z",
     "shell.execute_reply": "2023-09-05T14:26:52.013916Z"
    },
    "papermill": {
     "duration": 19.868613,
     "end_time": "2023-09-05T14:26:52.018667",
     "exception": false,
     "start_time": "2023-09-05T14:26:32.150054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/844 [00:00<?, ?it/s]/tmp/ipykernel_22/4062213598.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  target = (target-min(target))/(max(target) -min(target))\n",
      "100%|██████████| 844/844 [00:04<00:00, 178.08it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TileDataset(tile_xla[\"test\"])\n",
    "tile_xla_predictions = []\n",
    "model.eval()\n",
    "pbar = tqdm(range(len(dataset)))\n",
    "for i in pbar:\n",
    "    cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "    cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "    \n",
    "    out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "    tile_xla_predictions.append(np.argsort(out.detach().cpu().numpy())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5fbb07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T14:27:22.507231Z",
     "iopub.status.busy": "2023-09-05T14:27:22.506864Z",
     "iopub.status.idle": "2023-09-05T14:27:22.958192Z",
     "shell.execute_reply": "2023-09-05T14:27:22.957294Z"
    },
    "papermill": {
     "duration": 15.536171,
     "end_time": "2023-09-05T14:27:22.960224",
     "exception": false,
     "start_time": "2023-09-05T14:27:07.424053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TopConfigs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile:xla:d6f5f54247bd1e58a10b9e7062c636ab</td>\n",
       "      <td>0;22;21;20;19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tile:xla:e3a655daa38e34ec240df959b650ac16</td>\n",
       "      <td>252;1016;99;618;1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tile:xla:f8c2c1a1098b2a361c26df668b286c87</td>\n",
       "      <td>41;116;101;166;202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile:xla:4dd1716853ed46ee4e7d09ede1732de8</td>\n",
       "      <td>8766;1946;1474;8565;6580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile:xla:d0a69155b6340748c36724e4bfc34be3</td>\n",
       "      <td>655;624;151;159;215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>layout:nlp:random:60880ed76de53f4d7a1b960b24f2...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>layout:nlp:random:23559853d9702baaaacbb0c83fd3...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>layout:nlp:random:f6c146fc5cf10be4f3accbaca989...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>layout:nlp:random:32531d07a084b319dce484f53a4c...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>layout:nlp:random:3a0c5517a87df8d82fd637b83298...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ID  \\\n",
       "0            tile:xla:d6f5f54247bd1e58a10b9e7062c636ab   \n",
       "1            tile:xla:e3a655daa38e34ec240df959b650ac16   \n",
       "2            tile:xla:f8c2c1a1098b2a361c26df668b286c87   \n",
       "3            tile:xla:4dd1716853ed46ee4e7d09ede1732de8   \n",
       "4            tile:xla:d0a69155b6340748c36724e4bfc34be3   \n",
       "..                                                 ...   \n",
       "889  layout:nlp:random:60880ed76de53f4d7a1b960b24f2...   \n",
       "890  layout:nlp:random:23559853d9702baaaacbb0c83fd3...   \n",
       "891  layout:nlp:random:f6c146fc5cf10be4f3accbaca989...   \n",
       "892  layout:nlp:random:32531d07a084b319dce484f53a4c...   \n",
       "893  layout:nlp:random:3a0c5517a87df8d82fd637b83298...   \n",
       "\n",
       "                                            TopConfigs  \n",
       "0                                        0;22;21;20;19  \n",
       "1                                 252;1016;99;618;1037  \n",
       "2                                   41;116;101;166;202  \n",
       "3                             8766;1946;1474;8565;6580  \n",
       "4                                  655;624;151;159;215  \n",
       "..                                                 ...  \n",
       "889  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "890  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "891  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "892  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "893  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "\n",
       "[894 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
    "for i,filename in enumerate(tile_xla[\"test\"]['file'].values):\n",
    "    id = 'tile:xla:' +filename[:-4]\n",
    "    sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2937.87457,
   "end_time": "2023-09-05T14:27:40.593929",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-05T13:38:42.719359",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
